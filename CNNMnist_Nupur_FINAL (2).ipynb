{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: CNN for MNIST Digit Recognition\n",
    "\n",
    "**Objective:** Build a Convolutional Neural Network to classify handwritten digits\n",
    "\n",
    "**Dataset:** MNIST (70,000 grayscale images of digits 0-9)\n",
    "\n",
    "**Target:** Achieve >95% accuracy on test set\n",
    "\n",
    "**Time:** 60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "- How convolution and pooling layers work\n",
    "- Building CNN architecture from scratch\n",
    "- Training and evaluating image classification models\n",
    "- Visualizing learned filters and feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore the Data\n",
    "\n",
    "MNIST contains:\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "- Each image is 28x28 pixels, grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# TODO: Print the shapes of training and test sets\n",
    "# Expected output:\n",
    "# Training data shape: (60000, 28, 28)\n",
    "# Training labels shape: (60000,)\n",
    "# Test data shape: (10000, 28, 28)\n",
    "# Test labels shape: (10000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess the Data\n",
    "\n",
    "**Key preprocessing steps:**\n",
    "1. Reshape to add channel dimension (28, 28) → (28, 28, 1)\n",
    "2. Normalize pixel values from [0, 255] → [0, 1]\n",
    "3. Convert labels to categorical (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reshape data to add channel dimension\n",
    "# Hint: Use .reshape() with -1 for automatic batch size\n",
    "# X_train = ...\n",
    "# X_test = ...\n",
    "\n",
    "print(f\"New training shape: {X_train.shape}\")\n",
    "print(f\"New test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalize pixel values to [0, 1]\n",
    "# Hint: Divide by 255.0 to convert uint8 to float32\n",
    "# X_train = ...\n",
    "# X_test = ...\n",
    "\n",
    "print(f\"Min pixel value: {X_train.min()}\")\n",
    "print(f\"Max pixel value: {X_train.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert labels to categorical (one-hot encoding)\n",
    "# Hint: Use keras.utils.to_categorical()\n",
    "# y_train_cat = ...\n",
    "# y_test_cat = ...\n",
    "\n",
    "print(f\"Original label: {y_train[0]}\")\n",
    "print(f\"One-hot encoded: {y_train_cat[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the CNN Model\n",
    "\n",
    "**Architecture to implement:**\n",
    "1. Conv2D layer: 32 filters, 3x3 kernel, ReLU activation\n",
    "2. MaxPooling2D: 2x2 pool size\n",
    "3. Conv2D layer: 64 filters, 3x3 kernel, ReLU activation\n",
    "4. MaxPooling2D: 2x2 pool size\n",
    "5. Flatten layer\n",
    "6. Dense layer: 128 units, ReLU activation\n",
    "7. Dropout: 0.5\n",
    "8. Dense output layer: 10 units, softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build the CNN model using keras.Sequential\n",
    "# model = keras.Sequential([\n",
    "#     # First convolutional block\n",
    "#     ...\n",
    "#     \n",
    "#     # Second convolutional block\n",
    "#     ...\n",
    "#     \n",
    "#     # Fully connected layers\n",
    "#     ...\n",
    "# ])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compile the Model\n",
    "\n",
    "**Compilation parameters:**\n",
    "- Optimizer: Adam\n",
    "- Loss function: Categorical crossentropy\n",
    "- Metrics: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model.compile(\n",
    "#     optimizer=...,\n",
    "#     loss=...,\n",
    "#     metrics=[...]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model\n",
    "# Hint: Use validation_split=0.1 to monitor validation accuracy\n",
    "# Use epochs=10 and batch_size=128\n",
    "# history = model.fit(\n",
    "#     ...\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set and print accuracy and loss\n",
    "# Hint: Use model.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Make Predictions and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test[:20])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    color = 'green' if predicted_classes[i] == y_test[i] else 'red'\n",
    "    plt.title(f\"Pred: {predicted_classes[i]}\\nTrue: {y_test[i]}\", color=color)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Analyze Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find all misclassified examples in the test set\n",
    "# Hint: Use np.where() to find indices where predicted label != true label\n",
    "# Then print the total count and error rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some misclassified examples\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, idx in enumerate(misclassified[:20]):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Pred: {predicted_labels[idx]}\\nTrue: {y_test[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Misclassified Examples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Learned Filters (Optional)\n",
    "\n",
    "Let's see what patterns the first convolutional layer learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights from first convolutional layer\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "print(f\"Filter shape: {filters.shape}\")  # (3, 3, 1, 32)\n",
    "\n",
    "# Normalize filters for visualization\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters_normalized = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "# Plot first 32 filters\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    plt.imshow(filters_normalized[:, :, 0, i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Learned Filters from First Conv Layer', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fashion-MNIST Evaluation\n",
    "\n",
    "To further validate the robustness of the CNN model, it was also tested on the Fashion-MNIST dataset, which contains grayscale images of clothing items such as shirts, shoes, bags, and coats.\n",
    "\n",
    "Unlike handwritten digits, Fashion-MNIST images are visually more complex and share similar shapes across different classes. Because of this, classification becomes more challenging.\n",
    "\n",
    "The same CNN architecture trained on MNIST was reused here to understand how well the model generalizes to a different type of data.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Load Fashion-MNIST\n",
    "(x_train_f, y_train_f), (x_test_f, y_test_f) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize\n",
    "x_train_f = x_train_f / 255.0\n",
    "x_test_f = x_test_f / 255.0\n",
    "\n",
    "# Reshape\n",
    "x_train_f = x_train_f.reshape(-1,28,28,1)\n",
    "x_test_f = x_test_f.reshape(-1,28,28,1)\n",
    "\n",
    "# Train model on Fashion-MNIST\n",
    "history_f = model.fit(x_train_f, y_train_f, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate\n",
    "loss_f, acc_f = model.evaluate(x_test_f, y_test_f)\n",
    "print(\"Fashion-MNIST Test Accuracy:\", acc_f)\n",
    "```\n",
    "\n",
    "### Observation\n",
    "\n",
    "The accuracy on Fashion-MNIST is lower compared to MNIST because clothing items contain overlapping visual patterns (for example, shirts and coats look similar). This experiment shows that while CNNs perform exceptionally well on digit recognition, real-world image classification problems require deeper architectures, data augmentation, and additional regularization.\n",
    "\n",
    "This step highlights the importance of testing machine learning models on diverse datasets to ensure proper generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. **Why do we use MaxPooling layers?**  \n",
    "MaxPooling reduces the spatial dimensions of feature maps, which decreases computational cost and helps the model become invariant to small translations. It retains the most significant features while discarding less important information.\n",
    "\n",
    "2. **What happens if you remove the Dropout layer?**  \n",
    "Removing Dropout increases the risk of overfitting. The model may perform very well on training data but generalize poorly on unseen test data.\n",
    "\n",
    "3. **Why is the first Conv layer filter count (32) smaller than the second (64)?**  \n",
    "Initial convolution layers learn simple patterns such as edges and curves. Deeper layers capture more complex structures, so a higher number of filters is used to represent richer features.\n",
    "\n",
    "4. **How would you modify this for RGB images?**  \n",
    "The input shape must be changed from `(28,28,1)` to `(height,width,3)` since RGB images have three channels. Example:\n",
    "```python\n",
    "input_shape = (32, 32, 3)\n",
    "```\n",
    "\n",
    "5. **What does each filter in the first Conv layer detect?**  \n",
    "Each filter learns basic visual features such as horizontal edges, vertical edges, curves, and corners. These low‑level features are combined in deeper layers to recognize complete digits.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
